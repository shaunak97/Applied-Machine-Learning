{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your name and UFL email address\n",
    "name = 'enter your name'\n",
    "email = 'enter your email'\n",
    "\n",
    "name = 'solution' # ###- \n",
    "email = 'solution' # ###- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment 4 -- name: solution, email: solution\n",
      "\n",
      "### Python version: 3.8.5 (default, Jan 27 2021, 15:41:15) \n",
      "[GCC 9.3.0]\n",
      "### NumPy version: 1.19.5\n",
      "### Scikit-learn version: 0.24.0\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "if name == 'enter your name' or email == 'enter your email':\n",
    "    assert False, 'Enter your name & email first!'\n",
    "else:\n",
    "    print('Assignment 4 -- name: {}, email: {}\\n'.format(name, email))\n",
    "    \n",
    "    # Load packages we need\n",
    "    import sys\n",
    "    import os\n",
    "    import time\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import sklearn\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "    # Let's check our software versions\n",
    "    print('### Python version: ' + __import__('sys').version)\n",
    "    print('### NumPy version: ' + np.__version__)\n",
    "    print('### Scikit-learn version: ' + sklearn.__version__)\n",
    "    print('------------')\n",
    "\n",
    "\n",
    "    # load our packages / code\n",
    "    sys.path.insert(1, '../common/')\n",
    "    import utils\n",
    "    import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global parameters to control behavior of the pre-processing, ML, analysis, etc.\n",
    "seed = 42\n",
    "\n",
    "# deterministic seed for reproducibility\n",
    "##rng = np.random.default_rng(seed)  # best practice but not fully implemented in scikit-learn\n",
    "np.random.seed(seed)\n",
    "\n",
    "prop_vec = [14, 3, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Loading and Pre-processing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For this assignment we'll load the Bike Sharing dataset (hourly)\n",
    "### This dataset contains features of users bike sharing/rental on an hourly basis.\n",
    "### The task is to predict how many users are sharing/renting a bike."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17379 entries, 0 to 17378\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   season      16320 non-null  float64\n",
      " 1   year        16231 non-null  float64\n",
      " 2   month       16304 non-null  float64\n",
      " 3   hour        16254 non-null  float64\n",
      " 4   holiday     16277 non-null  float64\n",
      " 5   weekday     16282 non-null  float64\n",
      " 6   workingday  16297 non-null  float64\n",
      " 7   weathersit  16324 non-null  float64\n",
      " 8   temp        16242 non-null  float64\n",
      " 9   atemp       16271 non-null  float64\n",
      " 10  hum         16252 non-null  float64\n",
      " 11  windspeed   16281 non-null  float64\n",
      " 12  registered  16244 non-null  float64\n",
      " 13  nsqrtc      16263 non-null  float64\n",
      " 14  count       17379 non-null  int64  \n",
      "dtypes: float64(14), int64(1)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "### Note: this dataset has missing values (artificially introduced), which you'll need to fill in before you can train a model\n",
    "df = pd.read_csv('../data/bikesharehour.csv.gz', compression='gzip', header=0, na_values='?')\n",
    "\n",
    "# Check that we loaded the data as expected\n",
    "df_expected_shape = (17379, 15)\n",
    "\n",
    "assert df.shape == df_expected_shape, 'Unexpected shape of df!'\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>registered</th>\n",
       "      <th>nsqrtc</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  year  month  hour  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0     1.0   0.0    NaN   0.0      0.0      6.0         0.0         1.0   NaN   \n",
       "1     1.0   0.0    NaN   1.0      0.0      6.0         0.0         1.0   NaN   \n",
       "2     1.0   0.0    1.0   2.0      0.0      6.0         0.0         1.0   0.0   \n",
       "3     1.0   0.0    1.0   3.0      0.0      6.0         0.0         1.0   0.0   \n",
       "4     1.0   0.0    1.0   4.0      0.0      6.0         0.0         1.0   0.0   \n",
       "\n",
       "   atemp  hum  windspeed  registered  nsqrtc  count  \n",
       "0    0.0  0.0        0.0        13.0    -5.0     16  \n",
       "1    0.0  0.0        0.0        32.0    -8.0     40  \n",
       "2    0.0  0.0        0.0        27.0    -7.0     32  \n",
       "3    0.0  0.0        0.0        10.0    -5.0     13  \n",
       "4    0.0  0.0        0.0         1.0     0.0      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## what does the data look like?\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are some NaNs which we'll have to impute!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all the data as a numpy matrix\n",
    "all_xy = df.to_numpy()\n",
    "\n",
    "col_names = [c for c in df.columns]\n",
    "features = col_names[:-1]\n",
    "target = col_names[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: ['season', 'year', 'month', 'hour', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'registered', 'nsqrtc'] --- target: count\n"
     ]
    }
   ],
   "source": [
    "print('features: {} --- target: {}'.format(features, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1059, 1148, 1075, 1125, 1102, 1097, 1082, 1055, 1137, 1108, 1127,\n",
       "       1098, 1135, 1116,    0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many NaNs in each column?\n",
    "np.sum(np.isnan(all_xy), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe: no NaNs in the target/value column\n",
    "### About 1000+ NaNs in each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into x and y\n",
    "all_x_nan = all_xy[:,:-1]\n",
    "all_y = all_xy[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's impute the missing values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "###* put your code here (~2-3 lines) *###\n",
    "mf_imputer = SimpleImputer(missing_values=np.nan, strategy='median', copy=True)\n",
    "\n",
    "all_x_mf = mf_imputer.fit_transform(all_x_nan)\n",
    "all_x = all_x_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the shape is correct\n",
    "assert all_x.shape == (17379, 14)\n",
    "\n",
    "# check that there are no more NaNs\n",
    "assert np.sum(np.sum(np.isnan(all_x), axis=0)) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we start, we'll min-max normalize the features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(copy=True)\n",
    "scaler.fit(all_x) \n",
    "\n",
    "scaled_all_x = scaler.transform(all_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12166, 14), (12166,), (2607, 14), (2607,), (2606, 14), (2606,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into train, test, val\n",
    "train_x, train_y, test_x, test_y, val_x, val_y = utils.train_test_val_split(scaled_all_x, all_y, prop_vec, shuffle=True, seed=seed)\n",
    "\n",
    "# sanity check shapes\n",
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape, val_x.shape, val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 1] (35 points) Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train a linear regression model that we can use as a point of comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lrmodel = LinearRegression().fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's implement batch gradient descent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_gradient_descent(X, y, gradient_fn, lr_schedule_fn, num_iter=1000, stop_fn = None, verbose=False):\n",
    "    (n, m) = X.shape\n",
    "    theta = np.random.uniform(low=-1.0, high=1.0, size=(X.shape[1],1)) # initialize uniformly at random in [-1, 1]\n",
    "    \n",
    "    for i in range(0, num_iter):\n",
    "        eta = lr_schedule_fn(i) # learning rate\n",
    "        \n",
    "        gradient = gradient_fn(X, y, theta) # calculate gradient vector\n",
    "        assert gradient.shape == theta.shape\n",
    "        \n",
    "        prev_theta = theta \n",
    "        \n",
    "        # update theta (actual gradient descent step)\n",
    "        theta = theta - eta * gradient\n",
    "        \n",
    "        # compute diff \n",
    "        diff = theta - prev_theta\n",
    "        l2ndiff = np.linalg.norm(diff)\n",
    "        \n",
    "        if verbose and i % (num_iter/20) == 0:\n",
    "            print('Iter {}, learning rate: {:.6f}, diff in theta (L2-norm): {:.6f}.'.format(i, eta, l2ndiff))\n",
    "            \n",
    "        if stop_fn is not None and stop_fn(diff):\n",
    "            if verbose:\n",
    "                print('Stop condition reached (iter {}).'.format(i))\n",
    "            break\n",
    "    \n",
    "    return theta.reshape(-1,), i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1a] (5 points) Define a constant learning rate schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a constant schedule, it should always return the learning rate eta (regardless of iteration)\n",
    "def constant_lr_schedule(eta, iteration):\n",
    "    ###* put your code here (~1 line) *###\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1b] (20 points) Implement gradient_mse() which calculates the gradient vector of MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For this you'll want to go back to the course slides (e.g., lecture 10 slide 7) or spend some time figuring out the gradient of MSE \n",
    "### (the loss) with respect to the parameters (i.e., theta which includes the weights vector w and bias b)\n",
    "### Note: asserts are there to help you ensure that things have the right shape. \n",
    "### If you get shape errors when running your code, you should think about what shape each component of the gradient should have.\n",
    "def gradient_mse(X, y, theta):\n",
    "    (n, m) = X.shape\n",
    "    \n",
    "    y = y.reshape(-1,1)\n",
    "    assert y.shape == (n,1)\n",
    "    assert theta.shape == (m,1)\n",
    "    \n",
    "    ### Recall that the gradient of MSE is: 2/n X^T (θ X - y)   (note: θ = theta)\n",
    "    ###* put your code here (~1-3 lines) *###\n",
    "    \n",
    "    # for this to work, we need the term θ X - y to have shape (n,1)\n",
    "    # given the shapes of X (n,m) and theta (m,1), we need to multiply X by theta on the right\n",
    "    res = np.dot(X, theta) - y\n",
    "\n",
    "    return 2.0/n * np.dot(X.T, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's train the model (theta) using batch_gradient_descent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, learning rate: 0.050000, diff in theta (L2-norm): 36.157992.\n",
      "Iter 2500, learning rate: 0.050000, diff in theta (L2-norm): 0.015673.\n",
      "Iter 5000, learning rate: 0.050000, diff in theta (L2-norm): 0.000254.\n",
      "Iter 7500, learning rate: 0.050000, diff in theta (L2-norm): 0.000080.\n",
      "Iter 10000, learning rate: 0.050000, diff in theta (L2-norm): 0.000079.\n",
      "Iter 12500, learning rate: 0.050000, diff in theta (L2-norm): 0.000077.\n",
      "Iter 15000, learning rate: 0.050000, diff in theta (L2-norm): 0.000075.\n",
      "Iter 17500, learning rate: 0.050000, diff in theta (L2-norm): 0.000074.\n",
      "Iter 20000, learning rate: 0.050000, diff in theta (L2-norm): 0.000072.\n",
      "Iter 22500, learning rate: 0.050000, diff in theta (L2-norm): 0.000071.\n",
      "Iter 25000, learning rate: 0.050000, diff in theta (L2-norm): 0.000070.\n",
      "Iter 27500, learning rate: 0.050000, diff in theta (L2-norm): 0.000068.\n",
      "Iter 30000, learning rate: 0.050000, diff in theta (L2-norm): 0.000067.\n",
      "Iter 32500, learning rate: 0.050000, diff in theta (L2-norm): 0.000065.\n",
      "Iter 35000, learning rate: 0.050000, diff in theta (L2-norm): 0.000064.\n",
      "Iter 37500, learning rate: 0.050000, diff in theta (L2-norm): 0.000063.\n",
      "Iter 40000, learning rate: 0.050000, diff in theta (L2-norm): 0.000061.\n",
      "Iter 42500, learning rate: 0.050000, diff in theta (L2-norm): 0.000060.\n",
      "Iter 45000, learning rate: 0.050000, diff in theta (L2-norm): 0.000059.\n",
      "Iter 47500, learning rate: 0.050000, diff in theta (L2-norm): 0.000058.\n"
     ]
    }
   ],
   "source": [
    "# add a constant feature of 1 to each row to account for the bias term\n",
    "X_with_b = np.c_[np.ones((train_x.shape[0],1)), train_x]\n",
    "\n",
    "grad_fn = gradient_mse\n",
    "\n",
    "# use a lambda to define the constant schedule with the learning rate baked in\n",
    "learning_rate = 0.05\n",
    "lr_sched_fn = lambda i: constant_lr_schedule(learning_rate, i)\n",
    "\n",
    "# actually run the gradient descent and store the result in theta\n",
    "theta, _ = batch_gradient_descent(X_with_b, train_y, grad_fn, lr_sched_fn, num_iter=50000, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1c] (5 points) Extract the parameters (w, b) from theta, then compare them to the parameters of the linear regression model (lrmodel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression model -- w: [ 19.048  9.152 -10.044  37.807 -9.086  6.724 -34.405 -26.372  9.858\n",
      " -2.772 -9.309  20.558  1000.480 -12.950], b: 17.438\n",
      "Batch Gradient Descent model -- w: [ 19.049  9.153 -10.044  37.809 -9.087  6.726 -34.407 -26.373  3.242\n",
      " -0.833 -9.309  20.557  1000.481 -12.957], b: 17.442\n"
     ]
    }
   ],
   "source": [
    "# Print the weights and bias for both models\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "print('Linear Regression model -- w: {}, b: {:.3f}'.format(lrmodel.coef_, lrmodel.intercept_))\n",
    "\n",
    "### extract (w,b) from theta and print them\n",
    "###* put your code here (~2 lines) *###\n",
    "b = theta[0]\n",
    "w = theta[1:]\n",
    "\n",
    "print('Batch Gradient Descent model -- w: {}, b: {:.3f}'.format(w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 1d] (5 points) What do you notice? Is it expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer here *###\n",
    "#\n",
    "#\n",
    "# We see that the parameters are very similar, not identical but very similar. \n",
    "# This is expected as the underlying model is the same (linear regression).\n",
    "# Only the optimization procedure is different.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 2] (35 points) Implementing Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 2a] (10 points) Fill in the implementation of SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, gradient_fn, lr_schedule_fn, num_epochs=1000, stop_fn=None, verbose=False):\n",
    "    (n, m) = X.shape\n",
    "    theta = np.random.uniform(low=-1.0, high=1.0, size=(X.shape[1],1)) # initialize uniformly at random in [-1, 1]\n",
    "    \n",
    "    for i in range(0, num_epochs):\n",
    "        prev_theta = theta\n",
    "\n",
    "        # in each epoch go over the entire data\n",
    "        for j in range(0, n):\n",
    "            t = i*n+j\n",
    "            eta = lr_schedule_fn(t)\n",
    "            \n",
    "            ### Pick a single example out of the training data (X, y) uniformly at random, that is: \n",
    "            ### the feature vector and corresponding target/label\n",
    "            ### Call the feature vector 'xc' and the target/label 'yc'\n",
    "            ###* put your code here (~2-3 lines) *###\n",
    "            ridx = np.random.randint(n)\n",
    "            xc = X[ridx,:]\n",
    "            yc = y[ridx]\n",
    "            \n",
    "            assert xc.shape == (m,) and yc.shape == ()\n",
    "            \n",
    "            # calculate gradients\n",
    "            gradient = gradient_fn(xc.reshape(1,-1), yc.reshape(-1,1), theta) \n",
    "            assert gradient.shape == theta.shape   \n",
    "            \n",
    "            # update theta (actual gradient descent step)\n",
    "            theta = theta - eta * gradient\n",
    "\n",
    "        # compute diff \n",
    "        diff = theta - prev_theta\n",
    "        l2ndiff = np.linalg.norm(diff)\n",
    "\n",
    "        if verbose and i % (num_epochs/20) == 0:\n",
    "            print('Epoch {}, learning rate: {:.9f}, diff in theta (L2-norm): {:.6f}.'.format(i, eta, l2ndiff))\n",
    "\n",
    "        if stop_fn is not None and stop_fn(diff):\n",
    "            if verbose:\n",
    "                print('Stop condition reached (iter {}).'.format(i))\n",
    "            break\n",
    "    \n",
    "    return theta.reshape(-1,), i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train the model for 250 epochs with a constant learning schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, learning rate: 0.050000000, diff in theta (L2-norm): 1013.477021.\n",
      "Epoch 25, learning rate: 0.050000000, diff in theta (L2-norm): 108.732698.\n",
      "Epoch 50, learning rate: 0.050000000, diff in theta (L2-norm): 69.817389.\n",
      "Epoch 75, learning rate: 0.050000000, diff in theta (L2-norm): 61.468455.\n",
      "Epoch 100, learning rate: 0.050000000, diff in theta (L2-norm): 80.031508.\n",
      "Epoch 125, learning rate: 0.050000000, diff in theta (L2-norm): 54.006748.\n",
      "Epoch 150, learning rate: 0.050000000, diff in theta (L2-norm): 85.679083.\n",
      "Epoch 175, learning rate: 0.050000000, diff in theta (L2-norm): 58.227511.\n",
      "Epoch 200, learning rate: 0.050000000, diff in theta (L2-norm): 78.481088.\n",
      "Epoch 225, learning rate: 0.050000000, diff in theta (L2-norm): 108.616293.\n"
     ]
    }
   ],
   "source": [
    "# use a lambda to define the constant schedule with the learning rate baked in\n",
    "learning_rate = 0.05\n",
    "lr_sched_fn = lambda i: constant_lr_schedule(learning_rate, i)\n",
    "\n",
    "theta, _ = stochastic_gradient_descent(X_with_b, train_y, gradient_mse, lr_sched_fn, num_epochs=250, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression model -- w: [ 19.048  9.152 -10.044  37.807 -9.086  6.724 -34.405 -26.372  9.858\n",
      " -2.772 -9.309  20.558  1000.480 -12.950], b: 17.438\n",
      "Stochastic Gradient Descent model -- w: [ 20.069  3.310 -12.118  37.742  0.206 -11.093 -34.761 -50.529  18.165\n",
      "  0.477 -8.298  17.320  1015.943 -5.579], b: 40.086\n"
     ]
    }
   ],
   "source": [
    "b = theta[0]\n",
    "w = theta[1:]\n",
    "\n",
    "# Print the weights and bias for both models\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "print('Linear Regression model -- w: {}, b: {:.3f}'.format(lrmodel.coef_, lrmodel.intercept_))\n",
    "print('Stochastic Gradient Descent model -- w: {}, b: {:.3f}'.format(w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 2b] (10 points) Provide an explanation as to what is happening? Is the process converging? Explain why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide an explanation as to what is happening? Is the process converging? Explain why.\n",
    "###* put your answer here *###\n",
    "#\n",
    "#\n",
    "# The process does not seem to be converging. \n",
    "# This is because of the stochastic nature of the process combined with the fact that the learning rate is too high\n",
    "# If we introduce a non-constant learning schedule, we could decrease the learning rate over time.\n",
    "#\n",
    "# It's important to note that it is not necessarily the case that the model will have bad performance. \n",
    "# In fact, the weight of the most important feature is similar to that of lrmodel. \n",
    "# But the point is that the parameters vary wildly from one epoch to the next (even after 250 epochs of training).\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 2c] (5 points) Train the model with a simple learning schedule that decreases the learning rate over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, learning rate: 0.000449256, diff in theta (L2-norm): 425.381763.\n",
      "Epoch 25, learning rate: 0.000088744, diff in theta (L2-norm): 5.112551.\n",
      "Epoch 50, learning rate: 0.000063396, diff in theta (L2-norm): 1.771860.\n",
      "Epoch 75, learning rate: 0.000051944, diff in theta (L2-norm): 1.162849.\n",
      "Epoch 100, learning rate: 0.000045065, diff in theta (L2-norm): 0.600628.\n",
      "Epoch 125, learning rate: 0.000040352, diff in theta (L2-norm): 1.013407.\n",
      "Epoch 150, learning rate: 0.000036863, diff in theta (L2-norm): 0.662578.\n",
      "Epoch 175, learning rate: 0.000034146, diff in theta (L2-norm): 0.407062.\n",
      "Epoch 200, learning rate: 0.000031954, diff in theta (L2-norm): 0.574088.\n",
      "Epoch 225, learning rate: 0.000030136, diff in theta (L2-norm): 0.303901.\n"
     ]
    }
   ],
   "source": [
    "# use a lambda to define a simple schedule that decreases the learning rate over time\n",
    "learning_rate = 0.05\n",
    "lr_sched_fn = lambda t: learning_rate / (1 + np.sqrt(t))\n",
    "\n",
    "# actually run the stochastic_gradient_descent for 250 epochs and store the result in 'theta'\n",
    "# make sure to use the simple learning schedule defined above (lr_sched_fn). Also set verbose=True\n",
    "###* put your code here (~1 line) *###\n",
    "theta, _ = stochastic_gradient_descent(X_with_b, train_y, gradient_mse, lr_sched_fn, num_epochs=250, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression model -- w: [ 19.048  9.152 -10.044  37.807 -9.086  6.724 -34.405 -26.372  9.858\n",
      " -2.772 -9.309  20.558  1000.480 -12.950], b: 17.438\n",
      "Stochastic Gradient Descent model -- w: [ 19.305  9.667 -9.834  37.811 -9.173  6.625 -34.309 -26.351  0.003 -1.335\n",
      " -9.081  21.736  999.294 -12.957], b: 17.384\n"
     ]
    }
   ],
   "source": [
    "b = theta[0]\n",
    "w = theta[1:]\n",
    "\n",
    "# Print the weights and bias for both models\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "\n",
    "print('Linear Regression model -- w: {}, b: {:.3f}'.format(lrmodel.coef_, lrmodel.intercept_))\n",
    "print('Stochastic Gradient Descent model -- w: {}, b: {:.3f}'.format(w, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 2d] (10 points) Show that the model has similar performance as the linear regression model (lrmodel). For this, show the coefficient of determination, the RMSE, and the MedAE for both on the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR Train] R^2: 0.89, RMSE: 58.95, MedAE: 21.18\n",
      "[LR Val] R^2: 0.88, RMSE: 61.91, MedAE: 21.18\n",
      "\n",
      "[SGD Train] R^2: 0.89, RMSE: 58.95, MedAE: 21.24\n",
      "[SGD Val] R^2: 0.88, RMSE: 61.91, MedAE: 21.29\n"
     ]
    }
   ],
   "source": [
    "# given model parameters 'theta' and a feature matrix 'x', this will return predictions\n",
    "def predict_theta(theta, x):\n",
    "    b = theta[0]\n",
    "    w = theta[1:]\n",
    "    \n",
    "    assert w.shape[0] == x.shape[1]\n",
    "    \n",
    "    return np.dot(w, x.T) + b\n",
    "    \n",
    "from sklearn.metrics import r2_score, mean_squared_error, median_absolute_error\n",
    "\n",
    "### You can implement this however you like. A simple way is to define a function to calculate and print \n",
    "### the scores and then call it for each model and dataset (train or val). For example, this function could have \n",
    "### the following signature: 'def print_scores(desc, true_y, pred_y):'\n",
    "### Hint: use predict_theta() for getting predictions from the model trained with SGD.\n",
    "###* put your code here (~10 lines) *###\n",
    "def print_scores(desc, true_y, pred_y):\n",
    "    r2 = r2_score(true_y, pred_y)\n",
    "    rmse = mean_squared_error(true_y, pred_y, squared=False)\n",
    "    medae = median_absolute_error(true_y, pred_y)\n",
    "    \n",
    "    print('[{}] R^2: {:.2f}, RMSE: {:.2f}, MedAE: {:.2f}'.format(desc, r2, rmse, medae))\n",
    "    \n",
    "print_scores('LR Train', train_y, lrmodel.predict(train_x))\n",
    "print_scores('LR Val', val_y, lrmodel.predict(val_x))\n",
    "print()\n",
    "print_scores('SGD Train', train_y, predict_theta(theta, train_x))\n",
    "print_scores('SGD Val', val_y, predict_theta(theta, val_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 3] (20 points) Mini-Batch Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3a] (5 points) Complete the implementation of mini_batch_sgd to include a callback after each epoch. This callback will be useful to obtain information during the optimization process. If the callback function is defined, your code should call it with the proper arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch_sgd(X, y, gradient_fn, lr_schedule_fn, num_epochs=1000, batch_size=100, callback_fn=None, stop_fn=None, verbose=False):\n",
    "    \n",
    "    (n, m) = X.shape\n",
    "    theta = np.random.uniform(low=-1.0, high=1.0, size=(X.shape[1],1)) # initialize uniformly at random in [-1, 1]\n",
    "    \n",
    "    batch_size = np.minimum(n, batch_size)\n",
    "    \n",
    "    for epoch in range(0, num_epochs):\n",
    "        prev_theta = theta\n",
    "\n",
    "        # shuffle the data\n",
    "        pi = np.random.permutation(n)\n",
    "        Xshuf = X[pi,:]\n",
    "        yshuf = y[pi]\n",
    "        for batch_start in range(0, n, batch_size):\n",
    "            \n",
    "            batch_idx = batch_start/batch_size\n",
    "            bsidx = batch_start\n",
    "            beidx = np.minimum(n, bsidx + batch_size)\n",
    "            Xmb = Xshuf[bsidx:beidx,:]\n",
    "            ymb = yshuf[bsidx:beidx]\n",
    "            \n",
    "            eta = lr_schedule_fn(epoch*n + bsidx)\n",
    "            \n",
    "            # grab gradient vector\n",
    "            gradient = gradient_fn(Xmb, ymb, theta)\n",
    "            assert gradient.shape == theta.shape  \n",
    "            \n",
    "            # update theta (actual gradient descent step)\n",
    "            theta = theta - eta * gradient\n",
    "            \n",
    "        \n",
    "        ### If callback_fn is defined (not None), call it and pass it the current epoch and current set of parameters\n",
    "        ###* put your code here (~2 lines) *###\n",
    "        if callback_fn is not None:\n",
    "            callback_fn(epoch, theta)\n",
    "\n",
    "        # compute diff \n",
    "        diff = theta - prev_theta\n",
    "        l2ndiff = np.linalg.norm(diff)\n",
    "\n",
    "        if verbose and epoch % (num_epochs/20) == 0:\n",
    "            print('Epoch {}, learning rate: {:.9f}, diff in theta (L2-norm): {:.6f}.'.format(epoch, eta, l2ndiff))\n",
    "\n",
    "        if stop_fn is not None and stop_fn(diff):\n",
    "            if verbose:\n",
    "                print('Stop condition reached (iter {}).'.format(i))\n",
    "            break\n",
    "            \n",
    "    return theta.reshape(-1,), epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3b] (5 points) Fill in the implementation of the callback function to save the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's use the following plotting function to explore our loss during gradient descent\n",
    "def plot_process_data(proc_data, ylabel, xlim=None, ylim=None):\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(ylabel)\n",
    "\n",
    "    plt.plot(np.arange(proc_data.shape[0]), proc_data[:,0], 'b--', linewidth=3, label='Training')\n",
    "    plt.plot(np.arange(proc_data.shape[0]), proc_data[:,1], 'r:', linewidth=3, label='Validation')\n",
    "\n",
    "    plt.legend()\n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(ylim)    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# This will be our callback function. \n",
    "# After each epoch, this function gets called so we can check on the progress of gradient descent\n",
    "# We'll save the RMSE for both train and val in the 'rmse' array so we can plot it later\n",
    "def rmse_per_epoch(epoch, theta, rmse, train_x, train_y, val_x, val_y):\n",
    "    theta = theta.reshape(-1,)\n",
    "    pred_y = predict_theta(theta, train_x)\n",
    "    \n",
    "    ### compute the RMSE on the training data, store the result in 'rmse[epoch, 0]'\n",
    "    ###* put your code here (~2 lines) *###\n",
    "    train_rmse = mean_squared_error(train_y, pred_y, squared=False)\n",
    "    rmse[epoch, 0] = train_rmse\n",
    "    \n",
    "    pred_y = predict_theta(theta, val_x)\n",
    "    \n",
    "    ### compute the RMSE on the validation data, store the result in 'rmse[epoch, 1]'\n",
    "    ###* put your code here (~2 lines) *###\n",
    "    val_rmse = mean_squared_error(val_y, pred_y, squared=False)\n",
    "    rmse[epoch, 1] = val_rmse\n",
    "\n",
    "\n",
    "# params for gradient descent\n",
    "num_epochs = 500\n",
    "bsz = 100\n",
    "\n",
    "# define our array to store the rmse_data. One row per epoch, column 0 will be train, column 1 will be val.\n",
    "rmse_data = np.zeros((num_epochs,2))\n",
    "\n",
    "# define the callback function\n",
    "ecbfn = lambda i, t : rmse_per_epoch(i, t, rmse_data, train_x, train_y, val_x, val_y)\n",
    "\n",
    "# use a lambda to define a simple schedule that decreases the learning rate slowly over time\n",
    "learning_rate = 0.05\n",
    "lr_sched_fn = lambda t: learning_rate / (1 + np.log(1 + t)) \n",
    "\n",
    "theta, _ = mini_batch_sgd(X_with_b, train_y, grad_fn, lr_sched_fn, \n",
    "                          num_epochs=num_epochs, batch_size=bsz, callback_fn=ecbfn, verbose=False)\n",
    "\n",
    "# do the actual plotting\n",
    "plot_process_data(rmse_data, 'RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3c] (5 points) Does the process converge? Should the number of epochs be increased? What about the learning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer here *###\n",
    "#\n",
    "#\n",
    "# The process does converge. Looking at the two curves, it seems unlikely that more epochs would help. \n",
    "# The learning rate could be tweaked but it seems fine given the performance achieved\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 3d] (5 points) What do you conclude? Is it worth training a linear regression model this way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer here *###\n",
    "#\n",
    "#\n",
    "# It would be easier to just use the Normal Equation to train the model.\n",
    "# But this works...\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Task 4] (10 points) Use SGDRegressor to train a similar model to what you did in Task 3. Show that the performance of both models is comparable (show R^2, RMSE, MedAE for both train and val). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SGDReg Train] R^2: 0.89, RMSE: 58.97, MedAE: 21.46\n",
      "[SGDReg Val] R^2: 0.88, RMSE: 61.91, MedAE: 21.55\n",
      "\n",
      "[SGD (Manual) Train] R^2: 0.89, RMSE: 58.95, MedAE: 21.23\n",
      "[SGD (Manual) Val] R^2: 0.88, RMSE: 61.91, MedAE: 21.31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "### Tip: if you defined a print_scores() method for Task 2d, you can reuse it here!\n",
    "###* put your code here (~5 lines) *###\n",
    "sgdregressor = SGDRegressor().fit(train_x, train_y)\n",
    "\n",
    "print_scores('SGDReg Train', train_y, sgdregressor.predict(train_x))\n",
    "print_scores('SGDReg Val', val_y, sgdregressor.predict(val_x))\n",
    "print()\n",
    "print_scores('SGD (Manual) Train', train_y, predict_theta(theta, train_x))\n",
    "print_scores('SGD (Manual) Val', val_y, predict_theta(theta, val_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [CIS6930 Additional Task -- Task 5] (25 points): Ridge Regression with Mini-batch SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this task, you will implement ridge regression using mini-batch SGD as defined in Task 3. \n",
    "### The main task is to derive the gradient vector for Ridge Regression (L2 regularization with MSE as loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5a] (15 points) Implement the gradient_mse_ridge() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_mse_ridge(X, y, theta, lmbda):\n",
    "    (n, m) = X.shape\n",
    "    \n",
    "    y = y.reshape(-1,1)\n",
    "    assert y.shape == (n,1)\n",
    "    assert theta.shape == (m,1)\n",
    "    \n",
    "    ### Figure out the gradient for ridge regression and implement this function \n",
    "    ### (You can refer to the course slides: lecture 5 on linear models, slide 12.)\n",
    "    ### Note 1: use 'lmbda' (lambda) -- the regularization hyperparameter.\n",
    "    ### Note 2: normally we do not regularize the bias b, but if you cannot avoid it is acceptable to regularize it for this task.\n",
    "    ###* put your code here (~1-3 lines) *###  \n",
    "    res = y - np.dot(X, theta)\n",
    "\n",
    "    # the \"trick\" here to avoid regularizing the bias is just set to use zeros to pad the array to the correct length\n",
    "    # and then use theta[1:] so we take only the weights (without including the bias)\n",
    "    return - 2.0/n * np.dot(X.T, res) + 2*lmbda * np.r_[np.zeros((1,1)), theta[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's put some code to do the mini-batch sgd ridge regression training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_mbsgd_ridge(lmbda):\n",
    "    num_epochs = 1000\n",
    "    bsz = 100\n",
    "\n",
    "    rmse_data = np.zeros((num_epochs,2))\n",
    "\n",
    "    # define the callback function\n",
    "    ecbfn = lambda i, t : rmse_per_epoch(i, t, rmse_data, train_x, train_y, val_x, val_y)\n",
    "\n",
    "    # use a lambda to define a simple schedule that decreases the learning rate over time\n",
    "    learning_rate = 0.05\n",
    "    lr_sched_fn = lambda t: learning_rate / (1 + np.log(1 + t))\n",
    "\n",
    "    # bake in lambda into the gradient fn\n",
    "    grad_fn = lambda X, y, thet : gradient_mse_ridge(X, y, thet, lmbda)\n",
    "\n",
    "    theta, _ = mini_batch_sgd(X_with_b, train_y, grad_fn, lr_sched_fn, \n",
    "                              num_epochs=num_epochs, batch_size=bsz, callback_fn=ecbfn, verbose=False)\n",
    "\n",
    "    # do the actual plotting\n",
    "    plot_process_data(rmse_data, 'RMSE')\n",
    "\n",
    "    ### if you have defined print_scores above, you can uncomment the following lines.\n",
    "    print_scores('SGD (Manual) Train', train_y, predict_theta(theta, train_x))\n",
    "    print_scores('SGD (Manual) Val', val_y, predict_theta(theta, val_x))\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5b] (5 points) In theory, what is the effect of L2 regularization on the weights vector?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "###* put your answer here *###\n",
    "#\n",
    "#\n",
    "# It decreases the weights such that there are less extreme values in the weights (makes the vector look gaussian).\n",
    "# In other words, it shrinks the norm of the weights vector.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Task 5c] (5 points) Run mini-batch SGD for Ridge regression using whatever value of lambda you think is appropriate. Make sure that the process stills converges and that you end up with a model with a comparable performance to the ones you trained in previous tasks (but that still shows some effect from L2 regularization). Show the effect of regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SGD (Manual) Train] R^2: 0.85, RMSE: 70.77, MedAE: 35.21\n",
      "[SGD (Manual) Val] R^2: 0.84, RMSE: 72.71, MedAE: 35.55\n",
      "Linear Regression model -- w: [ 19.048  9.152 -10.044  37.807 -9.086  6.724 -34.405 -26.372  9.858\n",
      " -2.772 -9.309  20.558  1000.480 -12.950], b: 17.438\n",
      "Mini-batch SGD Ridge -- w: [ 35.392  28.793 -5.216  83.546 -8.932  7.040 -20.999 -38.893  0.098\n",
      " -0.299 -13.101  31.244  730.639 -11.840], b: 8.925\n",
      "\n",
      "Linear Regression: ||w||_2: 1002.86\n",
      "Mini-batch SGD Ridge (lambda=0.008): ||w||_2: 739.12\n"
     ]
    }
   ],
   "source": [
    "###* put your code here (~1 line) to set the value of lambda *###\n",
    "lmbda = 0.008\n",
    "\n",
    "\n",
    "theta = do_mbsgd_ridge(lmbda)\n",
    "\n",
    "b = theta[0]\n",
    "w = theta[1:]\n",
    "\n",
    "print('Linear Regression model -- w: {}, b: {:.3f}'.format(lrmodel.coef_, lrmodel.intercept_))\n",
    "print('Mini-batch SGD Ridge -- w: {}, b: {:.3f}\\n'.format(w, b))\n",
    "\n",
    "\n",
    "###* put your code/answer here *###\n",
    "#\n",
    "# We can see from printing the norm of the weights that the weights are less extreme than with ridge regression.\n",
    "# Linear Regression: ||w||_2: 1002.86\n",
    "# Mini-batch SGD Ridge (lambda=0.008): ||w||_2: 739.12\n",
    "#\n",
    "print('Linear Regression: ||w||_2: {:.2f}'.format(np.linalg.norm(lrmodel.coef_)))\n",
    "print('Mini-batch SGD Ridge (lambda={:.3f}): ||w||_2: {:.2f}'.format(lmbda, np.linalg.norm(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
